{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ5Qj-1l9P8V"
      },
      "source": [
        "# Data Import\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook shows how to import data into a DuckDB database. It uses the `duckdb` Python package to connect to a DuckDB database and import data from various formats, including CSV, JSON, DataFrame, parquet, GeoJSON, Shapefile, GeoParquet, and more.\n",
        "\n",
        "## Datasets\n",
        "\n",
        "The following datasets are used in this notebook. You don't need to download them, they can be accessed directly from the notebook.\n",
        "\n",
        "- [cities.csv](https://open.gishub.org/data/duckdb/cities.csv)\n",
        "- [countries.csv](https://open.gishub.org/data/duckdb/countries.csv)\n",
        "\n",
        "## Installation\n",
        "\n",
        "Uncomment the following cell to install the required packages if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Fqwz1ST9P8X"
      },
      "outputs": [],
      "source": [
        "# %pip install duckdb leafmap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFIjRC-O9P8Y"
      },
      "source": [
        "## Library Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkwLb9YP9P8Z"
      },
      "outputs": [],
      "source": [
        "import duckdb\n",
        "import leafmap\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0TqNH_t9P8Z"
      },
      "source": [
        "## Installing Extensions\n",
        "\n",
        "DuckDBâ€™s Python API provides functions for installing and loading extensions, which perform the equivalent operations to running the `INSTALL` and `LOAD` SQL commands, respectively. An example that installs and loads the [httpfs extension](https://duckdb.org/docs/extensions/httpfs) looks like follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmZmJ2Pe9P8Z"
      },
      "outputs": [],
      "source": [
        "con = duckdb.connect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eQUN_v79P8Z"
      },
      "outputs": [],
      "source": [
        "con.install_extension(\"httpfs\")\n",
        "con.load_extension(\"httpfs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5FmW4x29P8a"
      },
      "outputs": [],
      "source": [
        "con.install_extension(\"spatial\")\n",
        "con.load_extension(\"spatial\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wjOnKrz9P8a"
      },
      "source": [
        "## Downloading Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRDZHgVC9P8a"
      },
      "outputs": [],
      "source": [
        "url = \"https://open.gishub.org/data/duckdb/cities.zip\"\n",
        "leafmap.download_file(url, unzip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1-0Mhjx9P8a"
      },
      "source": [
        "## CSV Files\n",
        "\n",
        "CSV files can be read using the `read_csv` function, called either from within Python or directly from within SQL. By default, the `read_csv` function attempts to auto-detect the CSV settings by sampling from the provided file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_H0jD2G9P8a"
      },
      "outputs": [],
      "source": [
        "# read from a file using fully auto-detected settings\n",
        "con.read_csv('cities.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsAbZxPB9P8b"
      },
      "outputs": [],
      "source": [
        "# specify options on how the CSV is formatted internally\n",
        "con.read_csv('cities.csv', header=True, sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26600-BY9P8b"
      },
      "outputs": [],
      "source": [
        "# use the (experimental) parallel CSV reader\n",
        "con.read_csv('cities.csv', parallel=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QG74RPEb9P8b"
      },
      "outputs": [],
      "source": [
        "# directly read a CSV file from within SQL\n",
        "con.sql(\"SELECT * FROM 'cities.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnxIeM6y9P8b"
      },
      "outputs": [],
      "source": [
        "# call read_csv from within SQL\n",
        "con.sql(\"SELECT * FROM read_csv_auto('cities.csv')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkV_oVT29P8b"
      },
      "source": [
        "## JSON Files\n",
        "\n",
        "JSON files can be read using the `read_json` function, called either from within Python or directly from within SQL. By default, the `read_json` function will automatically detect if a file contains newline-delimited JSON or regular JSON, and will detect the schema of the objects stored within the JSON file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNDoei3V9P8b"
      },
      "outputs": [],
      "source": [
        "# read from a single JSON file\n",
        "con.read_json('cities.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk5Nqu_U9P8b"
      },
      "outputs": [],
      "source": [
        "# directly read a JSON file from within SQL\n",
        "con.sql(\"SELECT * FROM 'cities.json'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsDK0Gp79P8b"
      },
      "outputs": [],
      "source": [
        "# call read_json from within SQL\n",
        "con.sql(\"SELECT * FROM read_json_auto('cities.json')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k8gRhIj9P8b"
      },
      "source": [
        "## DataFrames\n",
        "\n",
        "DuckDB is automatically able to query a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1L-U2wT9P8b"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('cities.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj7xcgb79P8b"
      },
      "outputs": [],
      "source": [
        "con.sql('SELECT * FROM df').fetchall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Z3Mg959P8b"
      },
      "source": [
        "## Parquet Files\n",
        "\n",
        "Parquet files can be read using the `read_parquet` function, called either from within Python or directly from within SQL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8Bi7zaW9P8b"
      },
      "outputs": [],
      "source": [
        "# read from a single Parquet file\n",
        "con.read_parquet('cities.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAJFO6WM9P8c"
      },
      "outputs": [],
      "source": [
        "# directly read a Parquet file from within SQL\n",
        "con.sql(\"SELECT * FROM 'cities.parquet'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjdYTTEG9P8c"
      },
      "outputs": [],
      "source": [
        "# call read_parquet from within SQL\n",
        "con.sql(\"SELECT * FROM read_parquet('cities.parquet')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKKzSSD_9P8c"
      },
      "source": [
        "## GeoJSON Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06nK18tE9P8c"
      },
      "outputs": [],
      "source": [
        "con.sql('SELECT * FROM ST_Drivers()')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbwQArc79P8c"
      },
      "outputs": [],
      "source": [
        "con.sql(\"SELECT * FROM ST_Read('cities.geojson')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Joj-UEns9P8c"
      },
      "outputs": [],
      "source": [
        "con.sql(\"FROM ST_Read('cities.geojson')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze5gbq_t9P8c"
      },
      "outputs": [],
      "source": [
        "con.sql(\"CREATE TABLE cities AS SELECT * FROM ST_Read('cities.geojson')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLaW05rw9P8c"
      },
      "outputs": [],
      "source": [
        "con.table('cities')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1wUpi129P8c"
      },
      "outputs": [],
      "source": [
        "con.sql(\"SELECT * FROM cities\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o-bqD4O9P8c"
      },
      "source": [
        "## Shapefiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBB50Mjc9P8c"
      },
      "outputs": [],
      "source": [
        "con.sql(\"SELECT * FROM ST_Read('cities.shp')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqwMG5hd9P8c"
      },
      "outputs": [],
      "source": [
        "con.sql(\"FROM ST_Read('cities.shp')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4OWvrPV9P8c"
      },
      "outputs": [],
      "source": [
        "con.sql(\n",
        "    \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cities2 AS\n",
        "        SELECT * FROM ST_Read('cities.shp')\n",
        "        \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EM2ZRqo9P8c"
      },
      "outputs": [],
      "source": [
        "con.table('cities2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDhrW-BM9P8f"
      },
      "outputs": [],
      "source": [
        "con.sql('SELECT * FROM cities2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQcBnzpF9P8f"
      },
      "source": [
        "## GeoParquet Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KyFFSwD9P8g"
      },
      "outputs": [],
      "source": [
        "con.sql(\"SELECT * FROM 'cities.parquet'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_qiGbu-9P8g"
      },
      "outputs": [],
      "source": [
        "con.sql(\n",
        "    \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS cities3 AS\n",
        "SELECT * EXCLUDE geometry, ST_GeomFromWKB(geometry)\n",
        "AS geometry FROM 'cities.parquet'\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgTWAv7x9P8g"
      },
      "outputs": [],
      "source": [
        "con.table('cities3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BquF6O8T9P8g"
      },
      "outputs": [],
      "source": [
        "con.sql(\n",
        "    \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS country AS\n",
        "SELECT * EXCLUDE geometry, ST_GeomFromWKB(geometry) FROM\n",
        "        's3://us-west-2.opendata.source.coop/google-research-open-buildings/v2/geoparquet-admin1/country=SSD/*.parquet'\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVO4uH5h9P8g"
      },
      "outputs": [],
      "source": [
        "con.table('country')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhKOJEWi9P8g"
      },
      "outputs": [],
      "source": [
        "con.sql('SELECT COUNT(*) FROM country')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwMFbQsV9P8g"
      },
      "source": [
        "## References\n",
        "\n",
        "- [DuckDB Data Ingestion](https://duckdb.org/docs/api/python/data_ingestion)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "geo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}